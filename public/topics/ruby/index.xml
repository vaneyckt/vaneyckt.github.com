<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ruby on vaneyckt.io</title>
    <link>https://vaneyckt.io/topics/ruby/</link>
    <description>Recent content in Ruby on vaneyckt.io</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Tom Van Eyck</copyright>
    <lastBuildDate>Thu, 17 Mar 2016 19:12:21 +0000</lastBuildDate>
    <atom:link href="https://vaneyckt.io/topics/ruby/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Ruby concurrency: in praise of the mutex</title>
      <link>https://vaneyckt.io/posts/ruby_concurrency_in_praise_of_the_mutex/</link>
      <pubDate>Thu, 17 Mar 2016 19:12:21 +0000</pubDate>
      
      <guid>https://vaneyckt.io/posts/ruby_concurrency_in_praise_of_the_mutex/</guid>
      <description>

&lt;p&gt;When reading about Ruby you will inevitably be introduced to the Global Interpreter Lock. This mechanism tends to come up in explanations of why Ruby threads run concurrently on a single core, rather than being scheduled across multiple cores in true parallel fashion. This single core scheduling approach also explains why adding threads to a Ruby program does not necessarily result in faster execution times.&lt;/p&gt;

&lt;p&gt;This post will start by explaining some of the details behind the GIL. Next up, we&amp;rsquo;ll take a look at the three crucial concepts of concurrency: atomicity, visibility, and ordering. While most developers are familiar with atomicity, the concept of visibility is often not very well understood. We will be going over these concepts in quite some detail and will illustrate how to address their needs through correct usage of the mutex data structure.&lt;/p&gt;

&lt;h3 id=&#34;parallelism-and-the-gil:ea5ce71b092b908f8e251c60020af72d&#34;&gt;Parallelism and the GIL&lt;/h3&gt;

&lt;p&gt;Ruby&amp;rsquo;s Global Interpreter Lock is a global lock around the execution of Ruby code. Before a Ruby thread can execute any code, it first needs to acquire this lock. A thread holding the GIL will be forced to release it after a certain amount of time, at which point the kernel can hand the GIL to another Ruby thread. As the GIL can only be held by one thread at a time, it effectively prevents two Ruby threads from being executed at the same time.&lt;/p&gt;

&lt;p&gt;Luckily Ruby comes with an optimization that forces threads to let go off the GIL when they find themselves waiting on blocking IO to complete. Such threads will use the &lt;a href=&#34;http://linux.die.net/man/2/ppoll&#34;&gt;ppoll system call&lt;/a&gt; to be notified when their blocking IO has finished. Only then will they make an attempt to reacquire the GIL again. This type of behavior holds true for all blocking IO calls, as well as backtick and system calls. So even with the Global Interpreter Lock, Ruby is still able to have moments of true parallelism.&lt;/p&gt;

&lt;p&gt;Note that the GIL is specific to the default Ruby interpreter (&lt;a href=&#34;https://en.wikipedia.org/wiki/Ruby_MRI&#34;&gt;MRI&lt;/a&gt;) which relies on a global lock to protect its internals from race conditions. The GIL also makes it possible to safely interface the MRI interpreter with C libraries that may not be thread-safe themselves. Other interpreters have taken different approaches to the concept of a global lock; &lt;a href=&#34;http://rubinius.com/&#34;&gt;Rubinius&lt;/a&gt; opts for a collection of fine-grained locks instead of a single global one, whereas &lt;a href=&#34;http://jruby.org/&#34;&gt;JRuby&lt;/a&gt; does not use global locking at all.&lt;/p&gt;

&lt;h3 id=&#34;concurrency-and-the-mutex:ea5ce71b092b908f8e251c60020af72d&#34;&gt;Concurrency and the Mutex&lt;/h3&gt;

&lt;p&gt;There are three crucial concepts to concurrency: atomicity, visibility, and ordering. We&amp;rsquo;ll be taking a look at how Ruby&amp;rsquo;s mutex data structure addresses these. It is worth pointing out that different languages tackle these concepts in different ways. As such, the mutex-centric approach described here is only guaranteed to work in Ruby.&lt;/p&gt;

&lt;h4 id=&#34;atomicity:ea5ce71b092b908f8e251c60020af72d&#34;&gt;Atomicity&lt;/h4&gt;

&lt;p&gt;Atomicity is probably the best-known concurrency concept. A section of code is said to atomically modify the state of an object if all other threads are unable to see any of the intermediate states of the object being modified. These other threads either see the state as it was before the operation, or they see the state as it is after the operation.&lt;/p&gt;

&lt;p&gt;In the example below we have created a &lt;code&gt;counters&lt;/code&gt; array that holds ten entries, each of which is set to zero. This array represents an object that we want to modify, and its entries represent its internal state. Let&amp;rsquo;s say we have five threads, each of which executes a loop for 100.000 iterations that increments every entry by one. Intuitively we&amp;rsquo;d expect the output of this to be an array with each entry set to 500.000. However, as we can see below, this is not the case.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;# atomicity.rb
counters = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]

threads = 5.times.map do
  Thread.new do
    100000.times do
      counters.map! { |counter| counter + 1 }
    end
  end
end
threads.each(&amp;amp;:join)

puts counters.to_s
# =&amp;gt; [500000, 447205, 500000, 500000, 500000, 500000, 203656, 500000, 500000, 500000]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The reason for this unexpected output is that &lt;code&gt;counters.map! { |counter| counter + 1 }&lt;/code&gt; is not atomic. For example, imagine that our first thread has just read the value of the first entry, incremented it by one, and is now getting ready to write this incremented value to the first entry of our array. However, before our thread can write this incremented value, it gets interrupted by the second thread. This second thread then goes on to read the current value of the first entry, increments it by one, and succeeds in writing the result back to the first entry of our array. Now we have a problem!&lt;/p&gt;

&lt;p&gt;We have a problem because the first thread got interrupted before it had a chance to write its incremented value to the array. When the first thread resumes, it will end up overwriting the value that the second thread just placed in the array. This will cause us to essentially lose an increment operation, which explains why our program output has entries in it that are less than 500.000.&lt;/p&gt;

&lt;p&gt;It should hopefully be clear that none of this would have happened if we had made sure that &lt;code&gt;counters.map! { |counter| counter + 1 }&lt;/code&gt; was atomic. This would have made it impossible for the second thread to just come in and modify the intermediate state of the &lt;code&gt;counters&lt;/code&gt; array.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;# atomicity.rb
mutex = Mutex.new
counters = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]

threads = 5.times.map do
  Thread.new do
    100000.times do
      mutex.synchronize do
        counters.map! { |counter| counter + 1 }
      end
    end
  end
end
threads.each(&amp;amp;:join)

puts counters.to_s
# =&amp;gt; [500000, 500000, 500000, 500000, 500000, 500000, 500000, 500000, 500000, 500000]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Atomicity can be accomplished by using a mutex as a locking mechanism that ensures no two threads can simultaneously execute the same section of code. The code above shows how we can prevent a thread executing &lt;code&gt;counters.map! { |counter| counter + 1 }&lt;/code&gt; from being interrupted by other threads wanting to execute the same code. Also, be sure to note that &lt;code&gt;mutex.synchronize&lt;/code&gt; only prevents a thread from being interrupted by others wanting to execute code wrapped inside the same &lt;code&gt;mutex&lt;/code&gt; variable!&lt;/p&gt;

&lt;h4 id=&#34;visibility:ea5ce71b092b908f8e251c60020af72d&#34;&gt;Visibility&lt;/h4&gt;

&lt;p&gt;Visibility determines when the results of the actions performed by a thread become visible to other threads. For example, when a thread wants to write an updated value to memory, that updated value may end up being put in a cache for a while until the kernel decides to flush it to main memory. Other threads that read from that memory will therefore end up with a stale value!&lt;/p&gt;

&lt;p&gt;The code below shows an example of the visibility problem. Here we have several threads flipping the boolean values in the &lt;code&gt;flags&lt;/code&gt; array over and over again. The code responsible for changing these values is wrapped inside a mutex, so we know the intermediate states of the &lt;code&gt;flags&lt;/code&gt; array won&amp;rsquo;t be visible to other threads. We would thus expect the output of this program to contain the same boolean value for every entry of this array. However, we shall soon see that this does not always hold true.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;# visibility.rb
mutex = Mutex.new
flags = [false, false, false, false, false, false, false, false, false, false]

threads = 50.times.map do
  Thread.new do
    100000.times do
      puts flags.to_s
      mutex.synchronize do
        flags.map! { |f| !f }
      end
    end
  end
end
threads.each(&amp;amp;:join)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ ruby visibility.rb &amp;gt; visibility.log
$ grep -Hnri &#39;true, false&#39; visibility.log | wc -l
    30
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This code will produce five million lines of output. We&amp;rsquo;ll use the &lt;code&gt;&amp;gt;&lt;/code&gt; operator to write all these lines to a file. Having done this, we can then &lt;code&gt;grep&lt;/code&gt; for inconsistencies in the output. We would expect every line of the output to contain an array with all its entries set to the same boolean value. However, it turns out that this only holds true for 99.9994% of all lines. Sometimes the flipped boolean values don&amp;rsquo;t get written to memory fast enough, causing other threads to read stale data. This is a great illustration of the visibility problem.&lt;/p&gt;

&lt;p&gt;Luckily we can solve this problem by using a &lt;a href=&#34;https://en.wikipedia.org/wiki/Memory_barrier&#34;&gt;memory barrier&lt;/a&gt;. A memory barrier enforces an ordering constraint on memory operations thereby preventing the possibility of reading stale data. In Ruby, a mutex not only acts as an atomic lock, but also functions as a memory barrier. When wanting to read the value of a variable being modified by multiple threads, a memory barrier will effectively tell your program to wait until all in-flight memory writes are complete. In practice this means that if we use a mutex when writing to a variable, we need to use this same mutex when reading from that variable as well.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;# visibility.rb
mutex = Mutex.new
flags = [false, false, false, false, false, false, false, false, false, false]

threads = 50.times.map do
  Thread.new do
    100000.times do
      mutex.synchronize do
        puts flags.to_s
      end
      mutex.synchronize do
        flags.map! { |f| !f }
      end
    end
  end
end
threads.each(&amp;amp;:join)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ ruby visibility.rb &amp;gt; visibility.log
$ grep -Hnri &#39;true, false&#39; visibility.log | wc -l
    0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As expected, this time we found zero inconsistencies in the output data due to us using the same mutex for both reading and writing the boolean values of the &lt;code&gt;flags&lt;/code&gt; array. Do keep in mind that not all languages allow for using a mutex as a memory barrier, so be sure to check the specifics of your favorite language before going off to write concurrent code.&lt;/p&gt;

&lt;h3 id=&#34;ordering:ea5ce71b092b908f8e251c60020af72d&#34;&gt;Ordering&lt;/h3&gt;

&lt;p&gt;As if dealing with visibility isn&amp;rsquo;t hard enough, the Ruby interpreter is also allowed to change the order of the instructions in your code in an attempt at optimization. Before I continue I should point out that there is no official specification for the Ruby language. This can make it hard to find information about topics such as this. So I&amp;rsquo;m just going to describe how I &lt;em&gt;think&lt;/em&gt; instruction reordering currently works in Ruby.&lt;/p&gt;

&lt;p&gt;Your Ruby code gets compiled to bytecode by the Ruby interpreter. The interpreter is free to reorder your code in an attempt to optimize it. This bytecode will then generate a set of CPU instructions, which &lt;a href=&#34;https://en.wikipedia.org/wiki/Out-of-order_execution&#34;&gt;the CPU is free to reorder&lt;/a&gt; as well. I wasn&amp;rsquo;t able to come up with example code that actually showcases this reordering behavior, so this next bit is going to be somewhat hand-wavy. Let&amp;rsquo;s say we were given the code shown below (&lt;a href=&#34;http://jeremymanson.blogspot.ie/2007/08/atomicity-visibility-and-ordering.html&#34;&gt;original source&lt;/a&gt;).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;# ordering.rb
a = false
b = false
threads = []

thr1 = Thread.new do
  a = true
  b = true
end

thr2 = Thread.new do
  r1 = b # could see true
  r2 = a # could see false
  r3 = a # could see true
  puts (r1 &amp;amp;&amp;amp; !r2) &amp;amp;&amp;amp; r3 # could print true
end

thr1.join
thr2.join
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Since there are a lot of ways for instruction reordering to take place, it is not impossible for &lt;code&gt;b = true&lt;/code&gt; to be executed before &lt;code&gt;a = true&lt;/code&gt;. In theory, this could therefore allow for &lt;code&gt;thr2&lt;/code&gt; to end up outputting &lt;code&gt;true&lt;/code&gt;. This is rather counterintuitive, as this would only be possible if the variable &lt;code&gt;b&lt;/code&gt; had changed value before the variable &lt;code&gt;a&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Luckily there is no need to worry too much about this. When looking at the code above, it should be obvious that code reordering is going to be the least of its problems. The lack of any kind of synchronization to help deal with atomicity and visibility issues in this threaded program is going to cause way bigger headaches than code reordering ever could.&lt;/p&gt;

&lt;p&gt;Those synchronization issues can be fixed by using a mutex. By introducing a mutex we are explicitly telling the interpreter and CPU how our code should behave, thus preventing any problematic code reordering from occurring. Dealing with atomicity and visibility issues will therefore implicitly prevent any dangerous code reordering.&lt;/p&gt;

&lt;h3 id=&#34;conclusion:ea5ce71b092b908f8e251c60020af72d&#34;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;I hope this post has helped show just how easy it can be to introduce bugs in concurrent code. In my experience, the concept of memory barriers is often poorly understood, which can result in introducing some incredibly hard to find bugs. Luckily, as we saw in this post, the mutex data structure can be a veritable panacea for addressing these issues in Ruby.&lt;/p&gt;

&lt;p&gt;Please feel free to contact me if you think I got anything wrong. While all of the above is correct to the best of my knowledge, the lack of an official Ruby specification can make it hard to locate information that is definitively without error.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to write your own rspec retry mechanism</title>
      <link>https://vaneyckt.io/posts/how_to_write_your_own_rspec_retry_mechanism/</link>
      <pubDate>Sun, 17 Jan 2016 20:17:35 +0000</pubDate>
      
      <guid>https://vaneyckt.io/posts/how_to_write_your_own_rspec_retry_mechanism/</guid>
      <description>

&lt;p&gt;Imagine you have an rspec test suite filled with &lt;a href=&#34;http://david.heinemeierhansson.com/2014/tdd-is-dead-long-live-testing.html&#34;&gt;system tests&lt;/a&gt;. Each system test simulates how a real user would interact with your app by opening a browser session through which it fills out text fields, clicks on buttons, and sends data to public endpoints. Unfortunately, browser drivers are not without bugs and sometimes your tests will fail because of these. Wouldn&amp;rsquo;t it be nice if we could automatically retry these failed tests?&lt;/p&gt;

&lt;p&gt;This article starts by investigating how rspec formatters can be used to help us keep track of failed tests. Next, we&amp;rsquo;ll use this information to take a first stab at creating a rake task that can automatically retry failed tests. Lastly, we&amp;rsquo;ll explore how to further improve our simple rake task so as to make it ready for use in production.&lt;/p&gt;

&lt;p&gt;Note that any code shown in this post is only guaranteed to work with rspec 3.3. In the past I&amp;rsquo;ve written similar code for other rspec versions as well though. So don&amp;rsquo;t worry, it shouldn&amp;rsquo;t be too hard to get all of this to work on whatever rspec version you find yourself using.&lt;/p&gt;

&lt;h3 id=&#34;rspec-formatters:827d6d4c89344577730dfb054dfd5b79&#34;&gt;Rspec formatters&lt;/h3&gt;

&lt;p&gt;Rspec generates its command line output by relying on formatters that receive messages on events like &lt;code&gt;example_passed&lt;/code&gt; and &lt;code&gt;example_failed&lt;/code&gt;. We can use these hooks to help us keep track of failed tests by having them write the descriptions of failed tests to a text file named &lt;code&gt;tests_failed&lt;/code&gt;. Our &lt;code&gt;FailureFormatter&lt;/code&gt; class does just that.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;# failure_formatter.rb
require &#39;rspec/core/formatters/progress_formatter&#39;

class FailureFormatter &amp;lt; RSpec::Core::Formatters::ProgressFormatter
  RSpec::Core::Formatters.register self, :example_failed

  def example_failed(notification)
    super
    File.open(&#39;tests_failed&#39;, &#39;a&#39;) do |file|
      file.puts(notification.example.full_description)
    end
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We&amp;rsquo;ll soon have a look at how tests behave when we try to run them with the formatter shown above. But first, let&amp;rsquo;s prepare some example tests. We&amp;rsquo;ll create two tests. One of which will always pass, and another one which will always fail.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;# my_fake_tests_spec.rb
describe &#39;my fake tests&#39;, :type =&amp;gt; :feature do

  it &#39;this scenario should pass&#39; do
    expect(true).to eq true
  end

  it &#39;this scenario should fail&#39; do
    expect(false).to eq true
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Having done that, we can now run our tests with the &lt;code&gt;FailureFormatter&lt;/code&gt; we wrote earlier. As you can see below, we&amp;rsquo;ll have to pass both &lt;code&gt;--require&lt;/code&gt; and &lt;code&gt;--format&lt;/code&gt; params in order to get our formatter to work. I&amp;rsquo;m also using the &lt;code&gt;--no-fail-fast&lt;/code&gt; flag so as to prevent our test suite from exiting upon encountering its first failure.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ bundle exec rspec --require ./spec/formatters/failure_formatter.rb --format FailureFormatter --no-fail-fast
.F

Failures:

  1) my fake tests this scenario should fail
     Failure/Error: expect(false).to eq true

       expected: true
            got: false

       (compared using ==)
     # ./spec/my_fake_tests_spec.rb:8:in `block (2 levels) in &amp;lt;top (required)&amp;gt;&#39;

Finished in 0.02272 seconds (files took 0.0965 seconds to load)
2 examples, 1 failure

Failed examples:

rspec ./spec/my_fake_tests_spec.rb:7 # my fake tests this scenario should fail
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After running this, we should now have a &lt;code&gt;tests_failed&lt;/code&gt; file that contains a single line describing our failed test. As we can see in the snippet below, this is indeed the case.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ cat tests_failed

my fake tests this scenario should fail
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Take a moment to reflect on what we have just done. By writing just a few lines of code we have effectively created a logging mechanism that will help us keep track of failed tests. In the next section we will look at how we can make use of this mechanism to automatically rerun failed tests.&lt;/p&gt;

&lt;h3 id=&#34;first-pass-at-creating-the-retry-task:827d6d4c89344577730dfb054dfd5b79&#34;&gt;First pass at creating the retry task&lt;/h3&gt;

&lt;p&gt;In this section we will create a rake task that runs our rspec test suite and automatically retries any failed tests. The finished rake task is shown below. For now, have a look at this code and then we&amp;rsquo;ll go over its details in the next few paragraphs.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;require &#39;fileutils&#39;

task :rspec_with_retries, [:max_tries] do |_, args|
  max_tries = args[:max_tries].to_i

  # construct initial rspec command
  command = &#39;bundle exec rspec --require ./spec/formatters/failure_formatter.rb --format FailureFormatter --no-fail-fast&#39;

  max_tries.times do |t|
    puts &amp;quot;\n&amp;quot;
    puts &#39;##########&#39;
    puts &amp;quot;### STARTING TEST RUN #{t + 1} OUT OF A MAXIMUM OF #{max_tries}&amp;quot;
    puts &amp;quot;### executing command: #{command}&amp;quot;
    puts &#39;##########&#39;

    # delete tests_failed file left over by previous run
    FileUtils.rm(&#39;tests_failed&#39;, :force =&amp;gt; true)

    # run tests
    puts `#{command}`

    # early out
    exit 0 if $?.exitstatus.zero?
    exit 1 if (t == max_tries - 1)

    # determine which tests need to be run again
    failed_tests = []
    File.open(&#39;tests_failed&#39;, &#39;r&#39;) do |file|
      failed_tests = file.readlines.map { |line| &amp;quot;\&amp;quot;#{line.strip}\&amp;quot;&amp;quot; }
    end

    # construct command to rerun just the failed tests
    command  = [&#39;bundle exec rspec&#39;]
    command += Array.new(failed_tests.length, &#39;-e&#39;).zip(failed_tests).flatten
    command += [&#39;--require ./spec/formatters/failure_formatter.rb --format FailureFormatter --no-fail-fast&#39;]
    command = command.join(&#39; &#39;)
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The task executes the &lt;code&gt;bundle exec rspec&lt;/code&gt; command a &lt;code&gt;max_tries&lt;/code&gt; number of times. The first iteration runs the full rspec test suite with the &lt;code&gt;FailureFormatter&lt;/code&gt; class and writes the descriptions of failed tests to a &lt;code&gt;tests_failed&lt;/code&gt; file. Subsequent iterations read from this file and use the &lt;a href=&#34;https://relishapp.com/rspec/rspec-core/v/3-3/docs/command-line/example-option&#34;&gt;-e option&lt;/a&gt; to rerun the tests listed there.&lt;/p&gt;

&lt;p&gt;Note that these subsequent iterations use the &lt;code&gt;FailureFormatter&lt;/code&gt; as well. This means that any tests that failed during the second iteration will get written to the &lt;code&gt;tests_failed&lt;/code&gt; file to be retried by the third iteration. This continues until we reach the max number of iterations or until one of our iterations has all its tests pass.&lt;/p&gt;

&lt;p&gt;Every iteration deletes the &lt;code&gt;tests_failed&lt;/code&gt; file from the previous iteration. For this we use the &lt;code&gt;FileUtils.rm&lt;/code&gt; method with the &lt;code&gt;:force&lt;/code&gt; flag set to &lt;code&gt;true&lt;/code&gt;. This flag ensures that the program doesn&amp;rsquo;t crash in case the &lt;code&gt;tests_failed&lt;/code&gt; file doesn&amp;rsquo;t exist. The above code relies on backticks to execute the &lt;code&gt;bundle exec rspec&lt;/code&gt; subprocess. Because of this we need to use the global variable &lt;code&gt;$?&lt;/code&gt; to access the exit status of this subprocess.&lt;/p&gt;

&lt;p&gt;Below you can see the output of a run of our rake task. Notice how the first iteration runs both of our tests, whereas the second and third iterations rerun just the failed test. This shows our retry mechanism is indeed working as expected.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ rake rspec_with_retries[3]

##########
### STARTING TEST RUN 1 OUT OF A MAXIMUM OF 3
### executing command: bundle exec rspec --require ./spec/formatters/failure_formatter.rb --format FailureFormatter --no-fail-fast
##########
.F

Failures:

  1) my fake tests this scenario should fail
     Failure/Error: expect(false).to eq true

       expected: true
            got: false

       (compared using ==)
     # ./spec/my_fake_tests_spec.rb:8:in `block (2 levels) in &amp;lt;top (required)&amp;gt;&#39;

Finished in 0.02272 seconds (files took 0.0965 seconds to load)
2 examples, 1 failure

Failed examples:

rspec ./spec/my_fake_tests_spec.rb:7 # my fake tests this scenario should fail


##########
### STARTING TEST RUN 2 OUT OF A MAXIMUM OF 3
### executing command: bundle exec rspec -e &amp;quot;my fake tests this scenario should fail&amp;quot; --require ./spec/formatters/failure_formatter.rb --format FailureFormatter --no-fail-fast
##########
Run options: include {:full_description=&amp;gt;/my\ fake\ tests\ this\ scenario\ should\ fail/}
F

Failures:

  1) my fake tests this scenario should fail
     Failure/Error: expect(false).to eq true

       expected: true
            got: false

       (compared using ==)
     # ./spec/my_fake_tests_spec.rb:8:in `block (2 levels) in &amp;lt;top (required)&amp;gt;&#39;

Finished in 0.02286 seconds (files took 0.09094 seconds to load)
1 example, 1 failure

Failed examples:

rspec ./spec/my_fake_tests_spec.rb:7 # my fake tests this scenario should fail


##########
### STARTING TEST RUN 3 OUT OF A MAXIMUM OF 3
### executing command: bundle exec rspec -e &amp;quot;my fake tests this scenario should fail&amp;quot; --require ./spec/formatters/failure_formatter.rb --format FailureFormatter --no-fail-fast
##########
Run options: include {:full_description=&amp;gt;/my\ fake\ tests\ this\ scenario\ should\ fail/}
F

Failures:

  1) my fake tests this scenario should fail
     Failure/Error: expect(false).to eq true

       expected: true
            got: false

       (compared using ==)
     # ./spec/my_fake_tests_spec.rb:8:in `block (2 levels) in &amp;lt;top (required)&amp;gt;&#39;

Finished in 0.02378 seconds (files took 0.09512 seconds to load)
1 example, 1 failure

Failed examples:

rspec ./spec/my_fake_tests_spec.rb:7 # my fake tests this scenario should fail
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The goal of this section was to introduce the general idea behind our retry mechanism. There are however several shortcomings in the code that we&amp;rsquo;ve shown here. The next section will focus on identifying and fixing these.&lt;/p&gt;

&lt;h3 id=&#34;perfecting-the-retry-task:827d6d4c89344577730dfb054dfd5b79&#34;&gt;Perfecting the retry task&lt;/h3&gt;

&lt;p&gt;The code in the previous section isn&amp;rsquo;t all that bad, but there are a few things related to the &lt;code&gt;bundle exec rspec&lt;/code&gt; subprocess that we can improve upon. In particular, using backticks to initiate subprocesses has several downsides:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;the standard output stream of the subprocess gets written into a buffer which we cannot print until the subprocess finishes&lt;/li&gt;
&lt;li&gt;the standard error stream does not even get written to this buffer&lt;/li&gt;
&lt;li&gt;the backticks approach does not return the id of the subprocess to us&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This last downside is especially bad as not having the subprocess id makes it hard for us to cancel the subprocess in case the rake task gets terminated. This is why I prefer to use the &lt;a href=&#34;https://github.com/jarib/childprocess&#34;&gt;childprocess gem&lt;/a&gt; for handling subprocesses instead.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;require &#39;fileutils&#39;
require &#39;childprocess&#39;

task :rspec_with_retries, [:max_tries] do |_, args|
  max_tries = args[:max_tries].to_i

  # exit hook to ensure rspec process gets stopped when CTRL+C (SIGTERM is pressed)
  # needs to be set outside the times loop as otherwise each iteration would add its
  # own at_exit hook
  process = nil
  at_exit do
    process.stop unless process.nil?
  end

  # construct initial rspec command
  command = [&#39;bundle&#39;, &#39;exec&#39;, &#39;rspec&#39;, &#39;--require&#39;, &#39;./spec/formatters/failure_formatter.rb&#39;, &#39;--format&#39;, &#39;FailureFormatter&#39;, &#39;--no-fail-fast&#39;]

  max_tries.times do |t|
    puts &amp;quot;\n&amp;quot;
    puts &#39;##########&#39;
    puts &amp;quot;### STARTING TEST RUN #{t + 1} OUT OF A MAXIMUM OF #{max_tries}&amp;quot;
    puts &amp;quot;### executing command: #{command}&amp;quot;
    puts &#39;##########&#39;

    # delete tests_failed file left over by previous run
    FileUtils.rm(&#39;tests_failed&#39;, :force =&amp;gt; true)

    # run tests in separate process
    process = ChildProcess.build(*command)
    process.io.inherit!
    process.start
    process.wait

    # early out
    exit 0 if process.exit_code.zero?
    exit 1 if (t == max_tries - 1)

    # determine which tests need to be run again
    failed_tests = []
    File.open(&#39;tests_failed&#39;, &#39;r&#39;) do |file|
      failed_tests = file.readlines.map { |line| line.strip }
    end

    # construct command to rerun just the failed tests
    command  = [&#39;bundle&#39;, &#39;exec&#39;, &#39;rspec&#39;]
    command += Array.new(failed_tests.length, &#39;-e&#39;).zip(failed_tests).flatten
    command += [&#39;--require&#39;, &#39;./spec/formatters/failure_formatter.rb&#39;, &#39;--format&#39;, &#39;FailureFormatter&#39;, &#39;--no-fail-fast&#39;]
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As we can see from the line &lt;code&gt;process = ChildProcess.build(*command)&lt;/code&gt;, this gem makes it trivial to obtain the subprocess id. This then allows us to write an &lt;code&gt;at_exit&lt;/code&gt; hook that shuts this subprocess down upon termination of our rake task. For example, using ctrl+c to cease the rake task will now cause the rspec subprocess to stop as well.&lt;/p&gt;

&lt;p&gt;This gem also makes it super easy to inherit the stdout and stderr streams from the parent process (our rake task). This means that anything that gets written to the stdout and stderr streams of the subprocess will now be written directly to the stdout and stderr streams of our rake task. Or in other words, our rspec subprocess is now able to output directly to the rake task&amp;rsquo;s terminal session. Having made these improvements, our &lt;code&gt;rspec_with_retries&lt;/code&gt; task is now ready for use in production.&lt;/p&gt;

&lt;h3 id=&#34;conclusion:827d6d4c89344577730dfb054dfd5b79&#34;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;I hope this post helped some people out there who find themselves struggling to deal with flaky tests. Please note that a retry mechanism such as this is really only possible because of rspec&amp;rsquo;s powerful formatters. Get in touch if you have any examples of other cool things built on top of this somewhat underappreciated feature!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The disaster that is Ruby&#39;s timeout method</title>
      <link>https://vaneyckt.io/posts/the_disaster_that_is_rubys_timeout_method/</link>
      <pubDate>Sat, 19 Dec 2015 19:20:03 +0000</pubDate>
      
      <guid>https://vaneyckt.io/posts/the_disaster_that_is_rubys_timeout_method/</guid>
      <description>

&lt;p&gt;On paper, &lt;a href=&#34;http://ruby-doc.org/stdlib-2.1.1/libdoc/timeout/rdoc/Timeout.html#method-c-timeout&#34;&gt;Ruby&amp;rsquo;s timeout method&lt;/a&gt; looks like an incredibly useful piece of code. Ever had a network request occasionally slow down your entire program because it just wouldn&amp;rsquo;t finish? That&amp;rsquo;s where &lt;code&gt;timeout&lt;/code&gt; comes in. It provides a hard guarantee that a block of code will be finished within a specified amount of time.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;require &#39;timeout&#39;

timeout(5) do
  # block of code that should be interrupted if it takes more than 5 seconds
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There&amp;rsquo;s one thing the documentation doesn&amp;rsquo;t tell you though. If any of the lines in that block of code introduces side effects that rely on the execution of later lines of code to leave things in a stable state, then using the &lt;code&gt;timeout&lt;/code&gt; method is a great way to introduce instability in your program. Examples of this include pretty much any program that is not entirely without stateful information. Let&amp;rsquo;s have a closer look at this method to try and figure out what&amp;rsquo;s going on here exactly.&lt;/p&gt;

&lt;h3 id=&#34;exceptions-absolutely-anywhere:9337c8a75f66f40fb43aecac823e1f80&#34;&gt;Exceptions absolutely anywhere&lt;/h3&gt;

&lt;p&gt;The problem with &lt;code&gt;timeout&lt;/code&gt; is that it relies upon Ruby&amp;rsquo;s questionable ability to have one thread raise an exception &lt;em&gt;absolutely anywhere&lt;/em&gt; in an entirely different thread. The idea is that when you place code inside a &lt;code&gt;timeout&lt;/code&gt; block, this code gets wrapped inside a new thread that executes in the background while the main thread goes to sleep for 5 seconds. Upon waking, the main thread grabs the background thread and forcefully stops it by raising a &lt;code&gt;Timeout::Error&lt;/code&gt; exception on it (&lt;a href=&#34;https://github.com/ruby/ruby/blob/trunk/lib/timeout.rb#L72-L110&#34;&gt;actual implementation&lt;/a&gt;).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;# raising_exceptions.rb
# threads can raise exceptions in other threads
thr = Thread.new do
  puts &#39;...initializing resource&#39;
  sleep 1

  puts &#39;...using resource&#39;
  sleep 1

  puts &#39;...cleaning resource&#39;
  sleep 1
end

sleep 1.5
thr.raise(&#39;raising an exception in the thread&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ ruby raising_exeptions.rb

...initializing resource
...using resource
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The problem with this approach is that the main thread does not care what code the background thread is executing when it raises the exception. This means that the engineer responsible for the code that gets executed by the background thread needs to assume an exception can get thrown from &lt;em&gt;absolutely anywhere&lt;/em&gt; within her code. This is madness! No one can be expected to place exception catchers around every single block of code!&lt;/p&gt;

&lt;p&gt;The following code further illustrates the problem of being able to raise an exception &lt;em&gt;absolutely anywhere&lt;/em&gt;. Turns out that &lt;em&gt;absolutely anywhere&lt;/em&gt; includes locations like the inside of &lt;code&gt;ensure&lt;/code&gt; blocks. These locations are generally not designed for handling any exceptions at all. I hope you weren&amp;rsquo;t using an &lt;code&gt;ensure&lt;/code&gt; block to terminate your database connection!&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;# ensure_block.rb
# raising exceptions inside an ensure block of another thread
# note how we never finish cleaning the resource here
thr = Thread.new do
  begin
    puts &#39;...initializing resource&#39;
    sleep 1

    raise &#39;something went wrong&#39;

    puts &#39;...using resource&#39;
    sleep 1
  ensure
    puts &#39;...started cleaning resource&#39;
    sleep 1
    puts &#39;...finished cleaning resource&#39;
  end
end

sleep 1.5
thr.raise(&#39;raising an exception in the thread&#39;)

# prevent program from immediately terminating after raising exception
sleep 5
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ ruby ensure_blocks.rb

...initializing resource
...started cleaning resource
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;real-world-example:9337c8a75f66f40fb43aecac823e1f80&#34;&gt;Real world example&lt;/h3&gt;

&lt;p&gt;Recently, I spent a lot of time working with the &lt;a href=&#34;https://github.com/taf2/curb&#34;&gt;curb http client&lt;/a&gt;. I ended up wrapping quite a few of my curb calls within &lt;code&gt;timeout&lt;/code&gt; blocks because of tight time constraints. However, this caused great instability within the system I was working on. Sometimes a call would work, whereas other times that very same call would throw an exception about an invalid handle. It was this that caused me to start investigating the &lt;code&gt;timeout&lt;/code&gt; method.&lt;/p&gt;

&lt;p&gt;After having a bit of think, I came up with a proof of concept that showed beyond a doubt that the &lt;code&gt;timeout&lt;/code&gt; method was introducing instability in the very internals of my http client. The finished proof of concept code can look a bit complex, so rather than showing the final concept code straightaway, I&amp;rsquo;ll run you through my thought process instead.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s start with the basics and write some code that uses the http client to fetch a random google page. A randomized parameter is added to the google url in order to circumvent any client-side caching. The page fetch itself is wrapped inside a &lt;code&gt;timeout&lt;/code&gt; block as we are interested in testing whether the &lt;code&gt;timeout&lt;/code&gt; method is corrupting the http client.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;# basics.rb
# timeout doesn&#39;t get triggered
require &#39;curb&#39;
require &#39;timeout&#39;

timeout(1) do
  Curl.get(&amp;quot;http://www.google.com?foo=#{rand}&amp;quot;)
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This code will rarely timeout as a page fetch generally takes way less than one second to complete. This is why we&amp;rsquo;re going to wrap our page fetch inside an infinite while loop.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;# infinite_loop.rb
# timeout gets triggered and Timeout::Error exception gets thrown
require &#39;curb&#39;
require &#39;timeout&#39;

timeout(1) do
  while true
    Curl.get(&amp;quot;http://www.google.com?foo=#{rand}&amp;quot;)
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ ruby infinite_loop.rb

/Users/vaneyckt/.rvm/gems/ruby-2.0.0-p594/gems/curb-0.8.8/lib/curl/easy.rb:68:
  in &#39;perform&#39;: execution expired (Timeout::Error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The above code is now timing out and throwing a &lt;code&gt;Timeout::Error&lt;/code&gt; exception. Next we want to determine whether the timing out of a page fetch could corrupt the internal state of the http client, thereby causing problems for a subsequent page fetch. We&amp;rsquo;ll need to make lots of page fetches to test this, so we&amp;rsquo;re going to wrap all of our current code inside another infinite while loop. Furthermore, we don&amp;rsquo;t want any &lt;code&gt;Timeout::Error&lt;/code&gt; exceptions to break us out of this while loop, so we&amp;rsquo;re going to catch and ignore these exceptions inside the while loop we just created. This gives us our finished proof of concept code.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;# proof_of_concept.rb
# timeout corrupts the very internals of the curb http client
require &#39;curb&#39;
require &#39;timeout&#39;

while true
  begin
    timeout(1) do
      while true
        Curl.get(&amp;quot;http://www.google.com?foo=#{rand}&amp;quot;)
      end
    end
  rescue Timeout::Error =&amp;gt; e
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ ruby proof_of_concept.rb

/Users/vaneyckt/.rvm/gems/ruby-2.0.0-p594/gems/curb-0.8.8/lib/curl/easy.rb:67:
  in &#39;add&#39;: CURLError: The easy handle is already added to a multi handle
  (Curl::Err::MultiAddedAlready)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Running the above program will result in an exception being thrown after a few seconds. At some point, the &lt;code&gt;timeout&lt;/code&gt; method is causing a &lt;code&gt;Timeout::Error&lt;/code&gt; exception to be raised inside a critical code path of the http client. This badly timed &lt;code&gt;Timeout::Error&lt;/code&gt; exception leaves the client in an invalid state, which in turn causes the next page fetch to fail with the exception shown above. Hopefully this illustrates why you should avoid creating programs that can have &lt;code&gt;Timeout::Error&lt;/code&gt; exceptions pop up &lt;em&gt;absolutely anywhere&lt;/em&gt;.&lt;/p&gt;

&lt;h3 id=&#34;conclusion:9337c8a75f66f40fb43aecac823e1f80&#34;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;I hope this has convinced you there is nothing you can do to prevent &lt;code&gt;timeout&lt;/code&gt; from doing whatever it wants to your program&amp;rsquo;s internal state. There is just no way a program can deal with &lt;code&gt;Timeout::Error&lt;/code&gt; exceptions being able to potentially pop up &lt;em&gt;absolutely anywhere&lt;/em&gt;. The only time you can really get away with using timeouts is when writing functional code that does not rely on any state. In all other cases, it is best to just avoid timeouts entirely.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Iterating over a hash containing arrays</title>
      <link>https://vaneyckt.io/posts/iterating_over_a_hash_containing_arrays/</link>
      <pubDate>Tue, 15 Oct 2013 16:46:02 +0000</pubDate>
      
      <guid>https://vaneyckt.io/posts/iterating_over_a_hash_containing_arrays/</guid>
      <description>&lt;p&gt;Last week I was implementing some auditing functionality in a rails app. At some point I was writing a page that would display how the attributes of a given ActiveRecord object had been changed. One of my colleagues spotted this and pointed out the following neat bit of syntactic sugar in Ruby.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;changes = {:attribute_a =&amp;gt; [1, 2], :attribute_b =&amp;gt; [3, 4]}

changes.each do |attribute, (before, after)|
  puts &amp;quot;#{attribute}: #{before} - #{after}&amp;quot;
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I later learned you can even do things like this.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;data = {:foo =&amp;gt; [[1, 2], 3]}

data.each do |key, ((a, b), c)|
  puts &amp;quot;#{key}: #{a} - #{b} - #{c}&amp;quot;
end
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Regarding if statement scope in Ruby</title>
      <link>https://vaneyckt.io/posts/regarding_if_statement_scope_in_ruby/</link>
      <pubDate>Sat, 31 Aug 2013 20:22:58 +0000</pubDate>
      
      <guid>https://vaneyckt.io/posts/regarding_if_statement_scope_in_ruby/</guid>
      <description>&lt;p&gt;I recently learned that &lt;code&gt;if&lt;/code&gt; statements in Ruby do not introduce scope. This means that you can write code like shown below and it&amp;rsquo;ll work fine.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;# perfectly valid Ruby code
if true
  foo = 5
end

puts foo
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;At first this seemed a bit weird to me. It wasn&amp;rsquo;t until I read &lt;a href=&#34;http://programmers.stackexchange.com/questions/58900/why-if-statements-do-not-introduce-scope-in-ruby-1-9&#34;&gt;this&lt;/a&gt; that I realized Ruby was even more versatile than I had first thought. As it turns out, it is this somewhat unconventional scoping rule that allows us to conditionally replace methods.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;if foo == 5
  def some_method
    # do something
  end
else
  def some_method
    # do something else
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As well as conditionally modify implementations.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;if foo == 5
  class someClass
    # ...
  end
else
  module someModule
    # ...
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And that&amp;rsquo;s amazing!&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>